// deno_i2v_proxy v4

// deno_i2v_proxy v4 ä¸»è¦ä¿®æ”¹å†…å®¹æè¦ï¼š
// 1. å°è¯•æ˜¾ç¤ºç™¾åˆ†æ¯”è¿›åº¦ï¼š
//    - åœ¨è½®è¯¢Fal.aiä»»åŠ¡çŠ¶æ€æ—¶ï¼Œè„šæœ¬ç°åœ¨ä¼šæ£€æŸ¥å“åº”ä¸­æ˜¯å¦åŒ…å« `progress` å­—æ®µã€‚
//    - å¦‚æœ `progress` å­—æ®µå­˜åœ¨ä¸”ä¸ºæœ‰æ•ˆæ•°å­—ï¼Œè„šæœ¬ä¼šå°†å…¶è½¬æ¢ä¸ºç™¾åˆ†æ¯”ï¼Œå¹¶å°è¯•å‘é€ç±»ä¼¼ "è§†é¢‘å¤„ç†ä¸­... è¿›åº¦: XX% â–“â–“â–“â–‘â–‘â–‘â–‘â–‘â–‘â–‘" çš„æ¶ˆæ¯ã€‚
//    - å¦‚æœ `progress` å­—æ®µä¸å¯ç”¨ï¼Œåˆ™å›é€€åˆ°ä½¿ç”¨åŠ¨æ€è¡¨æƒ…ç¬¦å·æ¥æŒ‡ç¤ºå¤„ç†ä¸­ã€‚
// 2. ä¼˜åŒ–"å¤„ç†ä¸­"çš„æµå¼æ¶ˆæ¯ï¼š
//    - å¼•å…¥ä¸€ä¸ªç®€å•çš„æ—‹è½¬è¡¨æƒ…ç¬¦å·ï¼ˆspinnerï¼‰æ•°ç»„ï¼Œå¦‚ `["â³", "âš™ï¸", "ğŸ’¡", "ğŸ¬"]`ï¼Œåœ¨æ²¡æœ‰ç™¾åˆ†æ¯”è¿›åº¦æ—¶ï¼Œè½®æµæ˜¾ç¤ºè¿™äº›è¡¨æƒ…ï¼Œç»™ç”¨æˆ·ä¸€ç§åŠ¨æ€æ„Ÿã€‚
// 3. ç¾åŒ–æœ€ç»ˆæˆåŠŸ/å¤±è´¥æ¶ˆæ¯ï¼š
//    - å¯¹äºè§†é¢‘ç”ŸæˆæˆåŠŸçš„æ¶ˆæ¯ï¼Œé‡‡ç”¨ç”¨æˆ·å»ºè®®çš„æ ¼å¼ï¼ŒåŒ…å«âœ…å’ŒğŸ¥è¡¨æƒ…ç¬¦å·ï¼Œä»¥åŠMarkdownæ ¼å¼çš„è§†é¢‘é“¾æ¥ã€‚
//    - å¯¹äºè¶…æ—¶æˆ–å¤±è´¥çš„æ¶ˆæ¯ï¼Œä¹ŸåŠ å…¥é€‚å½“çš„æç¤ºæ€§è¡¨æƒ…ç¬¦å·ï¼Œå¦‚âš ï¸æˆ–âŒã€‚
// 4. ä¿ç•™v3çš„å¥å£®æ€§ä¿®æ”¹ï¼š
//    - ç»§ç»­å¤„ç†HTTP 413é”™è¯¯ï¼ˆå›¾ç‰‡è¿‡å¤§ï¼‰ã€‚
//    - ç»§ç»­å¯¹æµæ§åˆ¶å™¨çš„æ“ä½œè¿›è¡Œ`try...catch`ä¿æŠ¤ã€‚
//    - ä¿ç•™é’ˆå¯¹è§†é¢‘çš„è¾ƒé•¿è½®è¯¢è¶…æ—¶è®¾ç½®ã€‚
//    - ç»§ç»­æ­£ç¡®å¤„ç†Fal.aiçŠ¶æ€è½®è¯¢ä¸­çš„HTTP 202çŠ¶æ€ç ã€‚


const falApiKeysEnv = Deno.env.get("FAL_API_KEYS");
let AI_KEYS = [];
if (falApiKeysEnv) {
    AI_KEYS = falApiKeysEnv.split(',').map(key => key.trim()).filter(key => key.length > 0);
    if (AI_KEYS.length === 0) {
        console.warn("FAL_API_KEYS environment variable is set but contains no valid keys after parsing. Please ensure it's a comma-separated list of non-empty keys.");
    } else {
        console.log(`Successfully loaded ${AI_KEYS.length} FAL API Key(s) from environment variable.`);
    }
} else {
    console.warn("FAL_API_KEYS environment variable not set. AI functionality will be severely limited or fail. Please set it in your Deno Deploy project settings.");
}

const customAccessKeyEnv = Deno.env.get("MY_CUSTOM_ACCESS_KEY");
let CUSTOM_ACCESS_KEY = "";
if (customAccessKeyEnv) {
    CUSTOM_ACCESS_KEY = customAccessKeyEnv;
    console.log("Successfully loaded MY_CUSTOM_ACCESS_KEY from environment variable.");
} else {
    console.warn("MY_CUSTOM_ACCESS_KEY environment variable not set. Client authorization will likely fail. Please set it in your Deno Deploy project settings.");
}


export default {
    async fetch(request, env) {
      const url = new URL(request.url);
      const path = url.pathname;
      if (path === '/v1/chat/completions' && request.method === 'POST') {
        return await handleChatCompletions(request);
      } else if (path === '/v1/images/generations' && request.method === 'POST') {
        return await handleImageGenerations(request);
      } else if (path === '/v1/models' && request.method === 'GET') {
        return await listModels();
      } else {
        return new Response(JSON.stringify({
          error: { message: "Not Found", type: "not_found_error" }
        }), { status: 404, headers: { 'Content-Type': 'application/json' } });
      }
    }
  };

  const MODEL_URLS = {
    "FLUX-pro": {
      "submit_url": "https://queue.fal.run/fal-ai/flux-pro/v1.1-ultra",
      "status_base_url": "https://queue.fal.run/fal-ai/flux-pro",
      "image-to-image": false, "multi-image-input":false,
    },
    "recraft-v3": {
      "submit_url": "https://queue.fal.run/fal-ai/recraft-v3",
      "status_base_url": "https://queue.fal.run/fal-ai/recraft-v3",
      "image-to-image": false, "multi-image-input":false
    },
    "FLUX-1.1-pro": {
      "submit_url": "https://queue.fal.run/fal-ai/flux-pro/v1.1",
      "status_base_url": "https://queue.fal.run/fal-ai/flux-pro",
      "image-to-image": false, "multi-image-input":false
    },
    "ideogram": {
      "submit_url": "https://queue.fal.run/fal-ai/ideogram/v2",
      "status_base_url": "https://queue.fal.run/fal-ai/ideogram",
      "image-to-image": false, "multi-image-input":false
    },
    "dall-e-3": {
      "submit_url": "https://queue.fal.run/fal-ai/flux/dev",
      "status_base_url": "https://queue.fal.run/fal-ai/flux",
      "image-to-image": false, "multi-image-input":false
    },
    "google-imagen4": {
      "submit_url": "https://queue.fal.run/fal-ai/imagen4/preview",
      "status_base_url": "https://queue.fal.run/fal-ai/imagen4",
      "image-to-image": false, "multi-image-input":false
    },
    "flux-kontext-edit": {
      "submit_url": "https://queue.fal.run/fal-ai/flux-pro/kontext",
      "status_base_url": "https://queue.fal.run/fal-ai/flux-pro",
      "image-to-image": true, "multi-image-input":false
    },
    "flux-kontext-edit-multi": {
      "submit_url": "https://queue.fal.run/fal-ai/flux-pro/kontext/multi",
      "status_base_url": "https://queue.fal.run/fal-ai/flux-pro",
      "image-to-image": true, "multi-image-input":true
    },
    "hidream-i1-full": {
      "submit_url": "https://fal.run/fal-ai/hidream-i1-full/stream",
      "status_base_url": "https://queue.fal.run/fal-ai/hidream-i1-full",
      "image-to-image": false, "multi-image-input":false
    },
    "hidream-i1-full-edit": {
      "submit_url": "https://queue.fal.run/fal-ai/hidream-i1-full/image-to-image",
      "status_base_url": "https://queue.fal.run/fal-ai/hidream-i1-full",
      "image-to-image": true, "multi-image-input":false
    },
    "kling-video-v2.1-master": {
      "submit_url": "https://queue.fal.run/fal-ai/kling-video/v2.1/master/image-to-video",
      "status_base_url": "https://queue.fal.run/fal-ai/kling-video",
      "image-to-image": true, "multi-image-input": false, "is_video_model": true
    }
  };

  function getRandomApiKey() {
    if (AI_KEYS.length === 0) {
        console.error("getRandomApiKey: No FAL API keys available from environment variable FAL_API_KEYS.");
        return null;
    }
    const randomIndex = Math.floor(Math.random() * AI_KEYS.length);
    return AI_KEYS[randomIndex];
  }

  function extractAndValidateApiKey(request) {
    const authHeader = request.headers.get('Authorization') || '';
    let userKey;
    if (authHeader.startsWith('Bearer ')) userKey = authHeader.substring(7);
    else if (authHeader.startsWith('Key ')) userKey = authHeader.substring(4);
    else userKey = authHeader;

    if (!CUSTOM_ACCESS_KEY) {
        console.error("extractAndValidateApiKey: MY_CUSTOM_ACCESS_KEY is not set in environment. Cannot validate user key.");
        return { valid: false, userKey, error: "Server authorization misconfiguration." };
    }
    if (userKey !== CUSTOM_ACCESS_KEY) {
        console.warn(`extractAndValidateApiKey: Invalid user key provided: ${userKey ? userKey.substring(0,5)+'...' : 'empty'}`);
        return { valid: false, userKey, error: "Invalid API key." };
    }

    const randomApiKey = getRandomApiKey();
    if (!randomApiKey) {
        return { valid: false, userKey, error: "Server configuration error: No Fal.ai API keys available. Please check the FAL_API_KEYS environment variable on the server." };
    }
    return { valid: true, userKey, apiKey: randomApiKey };
  }

  function parseKlingParamsFromPrompt(promptText) {
    const params = {
        duration: "5",
        aspect_ratio: "16:9",
        negative_prompt: "blur, distort, and low quality",
        cfg_scale: 0.5,
        cleaned_prompt: promptText
    };
    let tempPrompt = ` ${promptText} `;
    const patterns = {
        duration: /(?:\s)(?:duration|dur):\s*("?(5|10)"?)(?=\s)/i,
        aspect_ratio: /(?:\s)(?:aspect_ratio|ar):\s*("?(16:9|9:16|1:1)"?)(?=\s)/i,
        negative_prompt: /(?:\s)(?:negative_prompt|np):\s*("(.*?)"|([^"\s]+(?:\s+[^"\s]+)*))(?=\s(?:duration:|dur:|aspect_ratio:|ar:|cfg_scale:|cfg:|$))/i,
        cfg_scale: /(?:\s)(?:cfg_scale|cfg):\s*(\d*\.?\d+)(?=\s)/i
    };
    let match;
    match = tempPrompt.match(patterns.duration);
    if (match) { params.duration = match[2]; tempPrompt = tempPrompt.replace(match[0], " "); }
    match = tempPrompt.match(patterns.aspect_ratio);
    if (match) { params.aspect_ratio = match[2]; tempPrompt = tempPrompt.replace(match[0], " "); }
    match = tempPrompt.match(patterns.negative_prompt);
    if (match) { params.negative_prompt = (match[2] || match[3]).replace(/"/g, '').trim(); tempPrompt = tempPrompt.replace(match[0], " ");}
    match = tempPrompt.match(patterns.cfg_scale);
    if (match) { const cfgVal = parseFloat(match[1]); if (!isNaN(cfgVal)) { params.cfg_scale = cfgVal; tempPrompt = tempPrompt.replace(match[0], " "); }}
    params.cleaned_prompt = tempPrompt.replace(/\s\s+/g, ' ').trim();
    return params;
  }

  // MODIFICATION: Helper function to create a simple text-based progress bar
  function createProgressBar(progressPercentage, length = 10) {
      const filledLength = Math.round(length * progressPercentage / 100);
      const emptyLength = length - filledLength;
      return `[${'â–“'.repeat(filledLength)}${'â–‘'.repeat(emptyLength)}] ${progressPercentage.toFixed(0)}%`;
  }

  async function handleChatCompletions(request) {
    const authResult = extractAndValidateApiKey(request);
    if (!authResult.valid) {
      return new Response(JSON.stringify({ error: { message: authResult.error || "Invalid API key.", type: "authentication_error" } }),
        { status: 401, headers: { 'Content-Type': 'application/json' } });
    }
    const { apiKey } = authResult;

    let openaiRequest;
    try { openaiRequest = await request.json(); }
    catch (e) { return new Response(JSON.stringify({ error: { message: "Invalid JSON in request body.", type: "invalid_request_error" } }),
        { status: 400, headers: { 'Content-Type': 'application/json' } });
    }

    const messages = openaiRequest.messages || [];
    const model = openaiRequest.model || 'dall-e-3';
    const stream = openaiRequest.stream === true;

    const modelIdToUse = MODEL_URLS[model] ? model : "dall-e-3";
    const modelConfig = MODEL_URLS[modelIdToUse];
    if (!modelConfig) {
        console.error(`Model configuration for "${modelIdToUse}" not found.`);
         return new Response(JSON.stringify({ error: { message: `Model configuration for "${modelIdToUse}" not found.`, type: "invalid_request_error" } }),
            { status: 400, headers: { 'Content-Type': 'application/json' } });
    }
    const isVideoModel = modelConfig.is_video_model || false;

    let prompt = "";
    let imageUrl = null;
    let imageUrls = [];

    for (let i = messages.length - 1; i >= 0; i--) {
      if (messages[i].role === 'user') {
        const content = messages[i].content;
        if (Array.isArray(content)) {
          for (const item of content) {
            if (item.type === 'text') prompt = item.text;
            else if (item.type === 'image_url' && item.image_url && item.image_url.url) {
              if (modelConfig["multi-image-input"]) imageUrls.push(item.image_url.url);
              else imageUrl = item.image_url.url;
            }
          }
        } else if (typeof content === 'string') prompt = content;
        break;
      }
    }

    if ((modelConfig["image-to-image"] || isVideoModel) && !imageUrl && imageUrls.length === 0) {
      for (let i = messages.length - 1; i >= 0; i--) {
        if (messages[i].role === 'assistant') {
          const assistantContent = messages[i].content;
          if (typeof assistantContent === 'string') {
            const imageMatches = assistantContent.match(/!\[.*?\]\((https?:\/\/[^\)]+)\)/g);
            if (imageMatches && imageMatches.length > 0) {
              const urlMatch = imageMatches[imageMatches.length - 1].match(/!\[.*?\]\((https?:\/\/[^\)]+)\)/);
              if (urlMatch && urlMatch[1]) { imageUrl = urlMatch[1]; break; }
            }
          }
        }
      }
    }
    
    let klingParams = null;
    let actualPromptForFal = prompt;

    if (isVideoModel) {
        if (!imageUrl) {
            return new Response(JSON.stringify({ error: { message: "è§†é¢‘ç”Ÿæˆéœ€è¦å›¾ç‰‡ï¼Œè¯·ä¸Šä¼ å›¾ç‰‡ã€‚", type: "invalid_request_error" } }),
                { status: 400, headers: { 'Content-Type': 'application/json' } });
        }
        klingParams = parseKlingParamsFromPrompt(prompt);
        actualPromptForFal = klingParams.cleaned_prompt;
        if (!actualPromptForFal) {
             return new Response(JSON.stringify({ error: { message: "è§†é¢‘ç”Ÿæˆéœ€è¦æè¿°æ€§æç¤ºè¯ï¼Œå³ä½¿ä½¿ç”¨äº†å‚æ•°ï¼Œæè¿°éƒ¨åˆ†ä¸èƒ½ä¸ºç©ºã€‚", type: "invalid_request_error" } }),
                { status: 400, headers: { 'Content-Type': 'application/json' } });
        }
    }

    if (!actualPromptForFal && !isVideoModel && !modelConfig["image-to-image"]) {
        return createStreamingDefaultResponse(model, "è¯·æè¿°æ‚¨æƒ³ç”Ÿæˆçš„å›¾ç‰‡ã€‚");
    }

    const falRequest = {};
    if (isVideoModel && klingParams) {
        falRequest.prompt = actualPromptForFal;
        falRequest.image_url = imageUrl;
        falRequest.duration = klingParams.duration;
        falRequest.aspect_ratio = klingParams.aspect_ratio;
        falRequest.negative_prompt = klingParams.negative_prompt;
        falRequest.cfg_scale = klingParams.cfg_scale;
    } else {
        falRequest.prompt = actualPromptForFal;
        falRequest.num_images = openaiRequest.n || 1;
        if (modelConfig["image-to-image"]) {
            if (modelConfig["multi-image-input"]) {
                if (imageUrls.length > 0) falRequest.image_urls = imageUrls;
                else if (imageUrl) falRequest.image_urls = [imageUrl];
            } else {
                if (imageUrl) falRequest.image_url = imageUrl;
                else if (imageUrls.length > 0) falRequest.image_url = imageUrls[0];
            }
            if (!falRequest.image_url && (!falRequest.image_urls || falRequest.image_urls.length === 0)) {
                 return new Response(JSON.stringify({ error: { message: "æ­¤æ¨¡å‹éœ€è¦å›¾ç‰‡è¿›è¡Œç¼–è¾‘/ç”Ÿæˆï¼Œå½“å‰æ¶ˆæ¯æˆ–å†å²è®°å½•ä¸­æœªæ‰¾åˆ°å›¾ç‰‡ã€‚", type: "invalid_request_error" } }),
                    { status: 400, headers: { 'Content-Type': 'application/json' } });
            }
        }
    }

    const falSubmitUrl = modelConfig.submit_url;
    const falStatusBaseUrl = modelConfig.status_base_url;

    try {
      const headers = { "Authorization": `Key ${apiKey}`, "Content-Type": "application/json" };
      const falResponse = await fetch(falSubmitUrl, { method: 'POST', headers: headers, body: JSON.stringify(falRequest) });
      
      if (falResponse.status === 413) {
          console.error(`Fal API Error (${falSubmitUrl}): 413 - Payload Too Large. Image likely too big.`);
          const errorMsg413 = "âŒ é”™è¯¯ï¼šä¸Šä¼ çš„å›¾ç‰‡æ–‡ä»¶è¿‡å¤§ï¼Œè¶…è¿‡äº†4MBçš„é™åˆ¶ã€‚è¯·å°è¯•ä½¿ç”¨æ›´å°çš„å›¾ç‰‡ã€‚";
          if (stream) {
              return createStreamingErrorResponse(modelIdToUse, errorMsg413);
          } else {
              return new Response(JSON.stringify({ error: { message: errorMsg413, type: "invalid_request_error", code: 413 } }),
                                 { status: 413, headers: { 'Content-Type': 'application/json' } });
          }
      }

      const responseText = await falResponse.text();
      if (falResponse.status !== 200 && falResponse.status !== 202) {
        console.error(`Fal API Error (${falSubmitUrl}): ${falResponse.status} - ${responseText.substring(0,500)}`);
        return new Response(JSON.stringify({ error: { message: `Fal API æäº¤é”™è¯¯ (çŠ¶æ€ ${falResponse.status}): ${responseText}`, type: "fal_api_error", code: falResponse.status } }),
                           { status: falResponse.status > 0 ? falResponse.status : 500 , headers: { 'Content-Type': 'application/json' } });
      }

      const falData = JSON.parse(responseText);
      const requestId = falData.request_id || (falData.request && falData.request.id);
      if (!requestId) {
        console.error("Fal å“åº”ä¸­æ²¡æœ‰ request_id:", falData);
        return new Response(JSON.stringify({ error: { message: "Fal API æäº¤åç¼ºå°‘ request_idã€‚", type: "fal_api_error" } }),
                           { status: 500, headers: { 'Content-Type': 'application/json' } });
      }
      
      let generatedArtifactUrls = [];
      const maxAttempts = isVideoModel ? 150 : 45; 
      const pollInterval = isVideoModel ? 4000 : 2500;
      // MODIFICATION: Spinner for progress messages
      const spinnerFrames = ["â³", "âš™ï¸", "ğŸ’¡", "ğŸ¬"];
      let spinnerIndex = 0;


      if (stream) {
        const readableStream = new ReadableStream({
          async start(controller) {
            const encoder = new TextEncoder();
            let streamClosedByError = false;

            const send = (data) => {
                if (streamClosedByError) return;
                try {
                    if (controller.desiredSize === null) {
                        console.warn("Stream controller is already closing/closed, cannot enqueue data:", JSON.stringify(data).substring(0,100));
                        streamClosedByError = true; return;
                    }
                    controller.enqueue(encoder.encode(`data: ${JSON.stringify(data)}\n\n`));
                } catch (e) {
                    if (e.name === 'TypeError' && (e.message.includes('cannot close or enqueue') || e.message.includes('is closing'))) {
                        console.warn("Stream controller was already closed or in a bad state when trying to enqueue. Client likely disconnected.", e.message);
                    } else { console.error("Error enqueuing data to stream:", e); }
                    streamClosedByError = true;
                }
            };
            
            send({ id: `chatcmpl-${requestId}`, object: "chat.completion.chunk", created: Math.floor(Date.now()/1000), model: modelIdToUse, choices: [{ index: 0, delta: { role: "assistant" }, finish_reason: null }] });

            let attempt = 0;
            let artifactGenerated = false;
            while (attempt < maxAttempts && !artifactGenerated && !streamClosedByError) {
              try {
                const statusUrl = `${falStatusBaseUrl}/requests/${requestId}/status`;
                const resultUrl = `${falStatusBaseUrl}/requests/${requestId}`;
                
                // MODIFICATION: Progress message logic
                if (attempt > 0) { // Don't send progress on first attempt immediately after role chunk
                    const statusResForProgress = await fetch(statusUrl, { headers: { "Authorization": `Key ${apiKey}` } }); // Fetch again for latest progress
                    let progressMsgContent = `è§†é¢‘ä»åœ¨åŠªåŠ›å¤„ç†ä¸­... ${spinnerFrames[spinnerIndex++ % spinnerFrames.length]}`;
                    if (statusResForProgress.status === 200 || statusResForProgress.status === 202) {
                        const currentStatusData = await statusResForProgress.json();
                        if (typeof currentStatusData.progress === 'number' && currentStatusData.progress >= 0 && currentStatusData.progress <= 1) {
                            const percentage = currentStatusData.progress * 100;
                            progressMsgContent = `è§†é¢‘å¤„ç†ä¸­... ${createProgressBar(percentage)}`;
                        }
                    }
                     send({ id: `chatcmpl-${requestId}`, object: "chat.completion.chunk", created: Math.floor(Date.now()/1000), model: modelIdToUse, choices: [{ index: 0, delta: { content: progressMsgContent }, finish_reason: null }] });
                }


                const statusRes = await fetch(statusUrl, { headers: { "Authorization": `Key ${apiKey}` } });
                
                if (statusRes.status === 200 || statusRes.status === 202) {
                  const statusData = await statusRes.json();

                  if (statusData.status === "FAILED" || (statusData.logs && statusData.logs.some(log => log.level === "ERROR"))) {
                    const errorMsg = statusData.logs?.find(l => l.level === "ERROR")?.message || statusData.error?.message || "Generation failed at Fal API.";
                    send({ id: `chatcmpl-${requestId}`, object: "chat.completion.chunk", created:Math.floor(Date.now()/1000), model: modelIdToUse, choices: [{ index:0, delta:{ content: `âŒ ç”Ÿæˆå¤±è´¥: ${errorMsg}` }, finish_reason: null }] });
                    artifactGenerated = true; break;
                  }
                  if (statusData.status === "COMPLETED") {
                    const resultRes = await fetch(resultUrl, { headers: { "Authorization": `Key ${apiKey}` } });
                    if (resultRes.status === 200) {
                      const resultData = await resultRes.json();
                      if (isVideoModel) {
                        if (resultData.video && resultData.video.url) generatedArtifactUrls.push(resultData.video.url);
                      } else {
                        if (resultData.images && Array.isArray(resultData.images) && resultData.images.length > 0) resultData.images.forEach(img => img && img.url && generatedArtifactUrls.push(img.url));
                        else if (resultData.image && resultData.image.url) generatedArtifactUrls.push(resultData.image.url);
                      }

                      if (generatedArtifactUrls.length > 0) {
                        artifactGenerated = true;
                        // MODIFICATION: Enhanced success message
                        let successMsg = isVideoModel ? `âœ… è§†é¢‘ç”ŸæˆæˆåŠŸ!\n\n` : (modelConfig["image-to-image"] ? `âœ… å›¾åƒç¼–è¾‘æˆåŠŸ!\n\n` : `âœ… å›¾åƒç”ŸæˆæˆåŠŸ!\n\n`);
                        send({ id: `chatcmpl-${requestId}`, object: "chat.completion.chunk", created: Math.floor(Date.now()/1000), model: modelIdToUse, choices: [{ index: 0, delta: { content: successMsg }, finish_reason: null }] });
                        generatedArtifactUrls.forEach((url, i) => {
                          if (i > 0) send({ id: `chatcmpl-${requestId}`, object: "chat.completion.chunk", created: Math.floor(Date.now()/1000), model: modelIdToUse, choices: [{ index: 0, delta: { content: "\n\n" }, finish_reason: null }] });
                          const linkContent = isVideoModel ? `ğŸ¥ [è§‚çœ‹è§†é¢‘](${url})` : `ğŸ–¼ï¸ [æŸ¥çœ‹å›¾ç‰‡ ${i+1}](${url})`;
                          send({ id: `chatcmpl-${requestId}`, object: "chat.completion.chunk", created: Math.floor(Date.now()/1000), model: modelIdToUse, choices: [{ index: 0, delta: { content: linkContent }, finish_reason: null }] });
                        });
                      } else { 
                        artifactGenerated = true; 
                        send({ id: `chatcmpl-${requestId}`, object: "chat.completion.chunk", created:Math.floor(Date.now()/1000), model: modelIdToUse, choices: [{ index:0, delta:{ content: "âš ï¸ ç”Ÿæˆä»»åŠ¡å·²å®Œæˆï¼Œä½†æœªèƒ½ä»Fal APIè·å–æœ‰æ•ˆçš„è¾“å‡ºURLã€‚" }, finish_reason: null }] }); 
                      }
                    } else { 
                        console.error(`Stream: Fal result fetch error: ${resultRes.status} ${await resultRes.text()}`); 
                        send({ id: `chatcmpl-${requestId}`, object: "chat.completion.chunk", created:Math.floor(Date.now()/1000), model: modelIdToUse, choices: [{ index:0, delta:{ content: `âŒ è·å–ç»“æœå¤±è´¥ (HTTP ${resultRes.status})ã€‚` }, finish_reason: null }] });
                        artifactGenerated = true;
                    }
                  }
                } else {
                  const errorText = await statusRes.text();
                  console.error(`Stream: Fal status check serious error: ${statusRes.status} - ${errorText}`);
                  send({ id: `chatcmpl-${requestId}`, object: "chat.completion.chunk", created:Math.floor(Date.now()/1000), model: modelIdToUse, choices: [{ index:0, delta:{ content: `âŒ æ£€æŸ¥ä»»åŠ¡çŠ¶æ€æ—¶å‡ºé”™ (HTTP ${statusRes.status}): ${errorText.substring(0,100)}` }, finish_reason: null }] });
                  artifactGenerated = true;
                }
              } catch (e) { 
                  console.error(`Stream: Polling exception: ${e.toString()}`); 
                  send({ id: `chatcmpl-${requestId}`, object: "chat.completion.chunk", created:Math.floor(Date.now()/1000), model: modelIdToUse, choices: [{ index:0, delta:{ content: `âŒ è½®è¯¢è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: ${e.toString().substring(0,100)}` }, finish_reason: null }] });
                  artifactGenerated = true;
              }
              if (!artifactGenerated && !streamClosedByError) { await new Promise(r => setTimeout(r, pollInterval)); attempt++; }
            }

            if (!artifactGenerated && !streamClosedByError) send({ id: `chatcmpl-${requestId}`, object: "chat.completion.chunk", created: Math.floor(Date.now()/1000), model: modelIdToUse, choices: [{ index: 0, delta: { content: isVideoModel ? "âš ï¸ è§†é¢‘ç”Ÿæˆè¶…æ—¶ï¼Œè¯·ç¨åå†è¯•æˆ–è°ƒæ•´å‚æ•°ã€‚" : "âš ï¸ å›¾åƒç”Ÿæˆè¶…æ—¶ï¼Œè¯·ç¨åå†è¯•æˆ–è°ƒæ•´å‚æ•°ã€‚" }, finish_reason: null }] });
            
            if (!streamClosedByError) {
                send({ id: `chatcmpl-${requestId}`, object: "chat.completion.chunk", created: Math.floor(Date.now()/1000), model: modelIdToUse, choices: [{ index: 0, delta: {}, finish_reason: "stop" }] });
                try {
                    if (controller.desiredSize !== null) {
                        controller.enqueue(encoder.encode("data: [DONE]\n\n"));
                        controller.close();
                    }
                } catch (e) {
                    if (e.name === 'TypeError' && (e.message.includes('cannot close or enqueue') || e.message.includes('is closing'))) {
                         console.warn("Stream controller was already closed when trying to send [DONE] or close.", e.message);
                    } else {
                         console.error("Error sending [DONE] or closing stream:", e);
                    }
                }
            }
          }
        });
        return new Response(readableStream, { headers: { 'Content-Type': 'text/event-stream', 'Cache-Control': 'no-cache', 'Connection': 'keep-alive' } });
      }

      // Non-streaming polling
      let attempt = 0;
      let artifactGeneratedNonStream = false;
      while (attempt < maxAttempts && !artifactGeneratedNonStream) {
        await new Promise(r => setTimeout(r, pollInterval)); 
        attempt++;
         try {
            const statusUrl = `${falStatusBaseUrl}/requests/${requestId}/status`;
            const resultUrl = `${falStatusBaseUrl}/requests/${requestId}`;
            const statusRes = await fetch(statusUrl, { headers: { "Authorization": `Key ${apiKey}` } });

            if (statusRes.status === 200 || statusRes.status === 202) {
                const statusData = await statusRes.json();
                 if (statusData.status === "FAILED" || (statusData.logs && statusData.logs.some(log => log.level === "ERROR"))) {
                    const errorMsg = statusData.logs?.find(l => l.level === "ERROR")?.message || statusData.error?.message || "Generation failed at Fal API.";
                    return new Response(JSON.stringify({ error: { message: `âŒ ç”Ÿæˆå¤±è´¥: ${errorMsg}`, type: "generation_failed" } }),
                                       { status: 500, headers: { 'Content-Type': 'application/json' } });
                }
                if (statusData.status === "COMPLETED") {
                    const resultRes = await fetch(resultUrl, { headers: { "Authorization": `Key ${apiKey}` } });
                    if (resultRes.status === 200) {
                        const resultData = await resultRes.json();
                         if (isVideoModel) {
                            if (resultData.video && resultData.video.url) generatedArtifactUrls.push(resultData.video.url);
                        } else {
                            if (resultData.images && Array.isArray(resultData.images) && resultData.images.length > 0) resultData.images.forEach(img => img && img.url && generatedArtifactUrls.push(img.url));
                            else if (resultData.image && resultData.image.url) generatedArtifactUrls.push(resultData.image.url);
                        }
                        if (generatedArtifactUrls.length > 0) {
                            artifactGeneratedNonStream = true; 
                        } else {
                             return new Response(JSON.stringify({ error: { message: "âš ï¸ ç”Ÿæˆä»»åŠ¡å·²å®Œæˆï¼Œä½†æœªèƒ½ä»Fal APIè·å–æœ‰æ•ˆçš„è¾“å‡ºURLã€‚", type: "generation_failed" } }),
                                       { status: 500, headers: { 'Content-Type': 'application/json' } });
                        }
                    } else {
                        const errorText = await resultRes.text();
                        console.error(`Non-Stream: Fal result fetch error: ${resultRes.status} - ${errorText}`);
                        return new Response(JSON.stringify({ error: { message: `âŒ è·å–ç»“æœå¤±è´¥ (HTTP ${resultRes.status}): ${errorText.substring(0,200)}`, type: "generation_failed" } }),
                                       { status: 500, headers: { 'Content-Type': 'application/json' } });
                    }
                }
            } else {
                const errorText = await statusRes.text();
                console.error(`Non-Stream: Fal status check serious error: ${statusRes.status} - ${errorText}`);
                return new Response(JSON.stringify({ error: { message: `âŒ æ£€æŸ¥ä»»åŠ¡çŠ¶æ€æ—¶å‡ºé”™ (HTTP ${statusRes.status}): ${errorText.substring(0,200)}`, type: "generation_failed" } }),
                                       { status: 500, headers: { 'Content-Type': 'application/json' } });
            }
        } catch (e) { 
            console.error(`Non-stream polling exception: ${e.toString()}`);
            return new Response(JSON.stringify({ error: { message: `âŒ è½®è¯¢è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: ${e.toString()}`, type: "server_error" } }),
                                       { status: 500, headers: { 'Content-Type': 'application/json' } });
        }
      }

      if (generatedArtifactUrls.length === 0) {
        return new Response(JSON.stringify({ id: `chatcmpl-${requestId}`, object: "chat.completion", created: Math.floor(Date.now()/1000), model: modelIdToUse,
          choices: [{ index: 0, message: { role: "assistant", content: isVideoModel ? "âš ï¸ æ— æ³•ç”Ÿæˆè§†é¢‘æˆ–è¶…æ—¶ï¼Œè¯·é‡è¯•ã€‚" : "âš ï¸ æ— æ³•ç”Ÿæˆå›¾åƒæˆ–è¶…æ—¶ï¼Œè¯·é‡è¯•ã€‚" }, finish_reason: "stop" }],
          usage: { prompt_tokens: Math.floor(prompt.length/4), completion_tokens: 20, total_tokens: Math.floor(prompt.length/4) + 20 }
        }), { headers: { 'Content-Type': 'application/json' } });
      }

      // MODIFICATION: Enhanced success message for non-streaming
      let content = isVideoModel ? `âœ… è§†é¢‘ç”ŸæˆæˆåŠŸ!\n\n` : (modelConfig["image-to-image"] ? `âœ… å›¾åƒç¼–è¾‘æˆåŠŸ!\n\n` : `âœ… å›¾åƒç”ŸæˆæˆåŠŸ!\n\n`);
      generatedArtifactUrls.forEach((url, i) => {
        if (i > 0) content += "\n\n";
        content += isVideoModel ? `ğŸ¥ [è§‚çœ‹è§†é¢‘](${url})` : `ğŸ–¼ï¸ [æŸ¥çœ‹å›¾ç‰‡ ${i+1}](${url})`;
      });
      
      return new Response(JSON.stringify({ id: `chatcmpl-${requestId}`, object: "chat.completion", created: Math.floor(Date.now()/1000), model: modelIdToUse,
        choices: [{ index: 0, message: { role: "assistant", content: content }, finish_reason: "stop" }],
        usage: { prompt_tokens: Math.floor(prompt.length/4), completion_tokens: Math.floor(content.length/4), total_tokens: Math.floor(prompt.length/4) + Math.floor(content.length/4) }
      }), { headers: { 'Content-Type': 'application/json' } });

    } catch (e) {
      console.error(`Overall exception in handleChatCompletions: ${e.toString()}`, e.stack);
      return new Response(JSON.stringify({ error: { message: `âŒ æœåŠ¡å™¨é”™è¯¯: ${e.toString()}`, type: "server_error" } }),
                         { status: 500, headers: { 'Content-Type': 'application/json' } });
    }
  }
  
  // MODIFICATION: Helper function for streaming error responses
  function createStreamingErrorResponse(model, errorMessageContent) {
    const requestId = Date.now().toString(36) + Math.random().toString(36).substring(2, 7);
    const stream = new ReadableStream({
      start(controller) {
        const encoder = new TextEncoder();
        const send = (data) => { try { if (controller.desiredSize !== null) controller.enqueue(encoder.encode(`data: ${JSON.stringify(data)}\n\n`)); } catch(e){ console.warn("Stream controller closed (error response):", e.message);}};
        send({ id: `chatcmpl-${requestId}`, object: "chat.completion.chunk", created:Math.floor(Date.now()/1000), model, choices: [{ index: 0, delta: { role: "assistant" }, finish_reason: null }] });
        send({ id: `chatcmpl-${requestId}`, object: "chat.completion.chunk", created:Math.floor(Date.now()/1000), model, choices: [{ index: 0, delta: { content: errorMessageContent }, finish_reason: null }] });
        send({ id: `chatcmpl-${requestId}`, object: "chat.completion.chunk", created:Math.floor(Date.now()/1000), model, choices: [{ index: 0, delta: {}, finish_reason: "stop" }] });
        try { if (controller.desiredSize !== null) { controller.enqueue(encoder.encode("data: [DONE]\n\n")); controller.close(); }} catch(e){ console.warn("Stream controller closed (error response close):", e.message);};
      }
    });
    return new Response(stream, { headers: { 'Content-Type': 'text/event-stream', 'Cache-Control': 'no-cache', 'Connection': 'keep-alive' } });
  }


  function createStreamingDefaultResponse(model, message) {
    // Uses the new createStreamingErrorResponse for consistency, but with a default message
    return createStreamingErrorResponse(model, message);
  }

  async function handleImageGenerations(request) {
    const authResult = extractAndValidateApiKey(request);
    if (!authResult.valid) {
      return new Response(JSON.stringify({ error: { message: authResult.error || "Invalid API key.", type: "authentication_error" } }),
        { status: 401, headers: { 'Content-Type': 'application/json' } });
    }

    let openaiRequest;
    try { openaiRequest = await request.json(); }
    catch (e) { return new Response(JSON.stringify({ error: { message: "å›¾åƒç”Ÿæˆè¯·æ±‚ä½“JSONæ— æ•ˆ", type: "invalid_request_error" } }),
        { status: 400, headers: { 'Content-Type': 'application/json' } });
    }

    const prompt = openaiRequest.prompt || '';
    const model = openaiRequest.model || 'dall-e-3';
    const stream = openaiRequest.stream === true;
    const imageUrl = openaiRequest.image_url || null; 

    const messages = [];
    let userContent = [];
    if (prompt) userContent.push({ type: "text", text: prompt });
    if (imageUrl) userContent.push({ type: "image_url", image_url: { url: imageUrl } });
    
    if (userContent.length === 0) {
         return new Response(JSON.stringify({ error: { message: "å›¾åƒç”Ÿæˆéœ€è¦Promptæˆ–image_urlã€‚", type: "invalid_request_error" } }),
            { status: 400, headers: { 'Content-Type': 'application/json' } });
    }
    messages.push({ role: "user", content: userContent });

    const chatPayload = { model, messages, stream, n: openaiRequest.n }; 
    
    const clonedHeaders = new Headers(request.headers);
    if (!clonedHeaders.has('Authorization')) {
        clonedHeaders.set('Authorization', `Key ${authResult.userKey}`);
    }
    
    const chatRequestUrl = new URL(request.url);
    chatRequestUrl.pathname = '/v1/chat/completions';

    const chatRequest = new Request(chatRequestUrl.toString(), {
        method: 'POST', headers: clonedHeaders, body: JSON.stringify(chatPayload)
    });
    return handleChatCompletions(chatRequest);
  }

  async function listModels() {
    const modelsData = Object.keys(MODEL_URLS).map(id => ({
        id: id, object: "model", created: Math.floor(Date.now() / 1000) - Math.floor(Math.random() * 3600 * 24 * 7), 
        owned_by: "fal-openai-adapter",
        permission: [], 
        root: id.split('-')[0],
        parent: null
    }));
    return new Response(JSON.stringify({ object: "list", data: modelsData }),
      { headers: { 'Content-Type': 'application/json' } });
  }